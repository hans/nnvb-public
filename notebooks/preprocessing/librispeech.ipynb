{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import copy\n",
    "import itertools\n",
    "import logging\n",
    "import re\n",
    "\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import seaborn as sns\n",
    "import soundfile as sf\n",
    "import transformers\n",
    "\n",
    "from src.utils import syllabifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style=\"whitegrid\", font_scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "split = \"train-clean-100\"\n",
    "data_dir = f\"data/librispeech/{split}\"\n",
    "alignment_dir = \"data/librispeech_alignments\"\n",
    "out_path = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets.disable_caching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\n",
    "    \"src/datasets/huggingface_librispeech.py\", data_dir=data_dir,\n",
    "    alignment_dir=alignment_dir)[split.replace(\"-\", \".\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.Wav2Vec2Tokenizer.from_pretrained(\"charsiu/tokenizer_en_cmu\")\n",
    "feature_extractor = transformers.Wav2Vec2FeatureExtractor(feature_size=1, sampling_rate=16000, padding_value=0.0, do_normalize=True, return_attention_mask=False)\n",
    "processor = transformers.Wav2Vec2Processor(feature_extractor=feature_extractor, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map UkE spellings to AmE spellings\n",
    "uke_to_ame_dict = requests.get(\"https://raw.githubusercontent.com/hyperreality/American-British-English-Translator/master/data/british_spellings.json\").json()    \n",
    "\n",
    "def americanize(word):\n",
    "    if word in uke_to_ame_dict:\n",
    "        return uke_to_ame_dict[word]\n",
    "    return word\n",
    "\n",
    "\n",
    "def americanize_item_orthography(item):\n",
    "    # NB this modifies only word_detail and not the full utterance\n",
    "    item[\"word_detail\"][\"utterance\"] = [americanize(word) for word in item[\"word_detail\"][\"utterance\"]]\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_phonemic_detail(item):\n",
    "    starts = copy(item[\"phonetic_detail\"][\"start\"])\n",
    "    stops = copy(item[\"phonetic_detail\"][\"stop\"])\n",
    "    utterances = copy(item[\"phonetic_detail\"][\"utterance\"])\n",
    "\n",
    "    # remove stress annotations\n",
    "    utterances = [re.sub(r\"\\d\", \"\", u) for u in utterances]\n",
    "\n",
    "    item[\"phonemic_detail\"] = {\n",
    "        \"start\": starts,\n",
    "        \"stop\": stops,\n",
    "        \"utterance\": utterances\n",
    "    }\n",
    "\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_phonetic_detail(item, idx, drop_phones=None, key=\"phonetic_detail\"):\n",
    "    \"\"\"\n",
    "    Group phonetic_detail entries according to the containing word.\n",
    "    \"\"\"\n",
    "    phonetic_detail = item[key]\n",
    "    word_detail = item[\"word_detail\"]\n",
    "\n",
    "    # Assure that each phone gets mapped to exactly one word. We'll arbitrarily map to the\n",
    "    # first word that contains the phone; this seems to most frequently match TIMIT annotation standards\n",
    "    phone_mask = np.zeros(len(phonetic_detail[\"start\"]), dtype=bool)\n",
    "    # Note that we also assign phonemes which span words to the leftmost word, consistent\n",
    "    # with this strategy\n",
    "\n",
    "    word_phonetic_detail = []\n",
    "    for start, stop, word in zip(word_detail[\"start\"], word_detail[\"stop\"], word_detail[\"utterance\"]):\n",
    "        word_phonetic_detail.append([])\n",
    "        for j, (phon_start, phon_stop, phon) in enumerate(zip(phonetic_detail[\"start\"], phonetic_detail[\"stop\"], phonetic_detail[\"utterance\"])):\n",
    "            if phone_mask[j]:\n",
    "                continue\n",
    "            elif drop_phones is not None and phon in drop_phones:\n",
    "                phone_mask[j] = True\n",
    "                continue\n",
    "            \n",
    "            # if the phoneme has start in this word, assign it to this word\n",
    "            if phon_start >= start and phon_start < stop:\n",
    "                phone_mask[j] = True\n",
    "                word_phonetic_detail[-1].append({\"phone\": phon, \"start\": phon_start, \"stop\": phon_stop})\n",
    "\n",
    "        if len(word_phonetic_detail[-1]) == 0:\n",
    "            if word == \"\":\n",
    "                # expected for these empty-word cases in librispeech annotations\n",
    "                continue\n",
    "            preceding_word_phones = \" \".join(phone[\"phone\"] for phone in word_phonetic_detail[-2]) if len(word_phonetic_detail) > 1 else \"\"\n",
    "            L.warning(f\"No phones found for word {word} in item {idx} ({item['text']}) (preceding word: {preceding_word_phones})\")\n",
    "\n",
    "    for unused_phone in np.flatnonzero(~phone_mask):\n",
    "        preceding_phones = \" \".join(phonetic_detail[\"utterance\"][max(0, unused_phone - 3):unused_phone])\n",
    "        following_phones = \" \".join(phonetic_detail[\"utterance\"][unused_phone + 1:min(len(phonetic_detail[\"utterance\"]), unused_phone + 4)])\n",
    "        unused_phone_str = phonetic_detail[\"utterance\"][unused_phone]\n",
    "        L.warning(f\"Unused phone {unused_phone_str} in item {idx} ({item['text']}) (preceding: {preceding_phones}, following: {following_phones})\")\n",
    "\n",
    "    # from pprint import pprint\n",
    "    # pprint(list(zip(word_detail[\"start\"], word_detail[\"stop\"], word_detail[\"utterance\"])))\n",
    "    # pprint(list(zip(phonetic_detail[\"start\"], phonetic_detail[\"stop\"], phonetic_detail[\"utterance\"])))\n",
    "    # pprint(word_phonetic_detail)\n",
    "\n",
    "    item[f\"word_{key}\"] = word_phonetic_detail\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_syllabic_detail(item):\n",
    "    word_syllables = []\n",
    "\n",
    "    # syllabifier doesn't use stress information so we can just use\n",
    "    # phonemic detail here\n",
    "    for word in item[\"word_phonemic_detail\"]:\n",
    "        phones = [ph[\"phone\"] for ph in word if ph[\"phone\"] not in [\"[SIL]\", \"\"]]\n",
    "        if len(phones) > 0:\n",
    "            syllables = syllabifier.syllabify(syllabifier.English, phones)\n",
    "\n",
    "            assert phones == list(itertools.chain.from_iterable(\n",
    "                [tuple(onset) + tuple(nucleus) + tuple(coda) for stress, onset, nucleus, coda in syllables]))\n",
    "            # print(syllables)\n",
    "            # word[\"syllables\"] = syllables\n",
    "\n",
    "            phoneme_idx, syllable_idx = 0, 0\n",
    "            syllable_dicts = []\n",
    "            for stress, onset, nucleus, coda in syllables:\n",
    "                syllable_phones = tuple(onset + nucleus + coda)\n",
    "                syllable_dict = {\n",
    "                    \"phones\": syllable_phones,\n",
    "                    \"idx\": syllable_idx,\n",
    "                    \"phoneme_start_idx\": phoneme_idx,\n",
    "                    \"phoneme_end_idx\": phoneme_idx + len(syllable_phones), # exclusive\n",
    "                    \"stress\": stress,\n",
    "\n",
    "                    \"start\": word[phoneme_idx][\"start\"],\n",
    "                    \"stop\": word[phoneme_idx + len(syllable_phones) - 1][\"stop\"],\n",
    "                }\n",
    "\n",
    "                # Add cross-reference data in word_phonemic_detail\n",
    "                for j, ph in enumerate(syllable_phones):\n",
    "                    word[phoneme_idx + j][\"syllable_idx\"] = syllable_idx\n",
    "                    word[phoneme_idx + j][\"idx_in_syllable\"] = j\n",
    "                    word[phoneme_idx + j][\"syllable_phones\"] = tuple(syllable_phones)\n",
    "                    word[phoneme_idx + j][\"stress\"] = stress\n",
    "                    word[phoneme_idx + j][\"syllable_start\"] = syllable_dict[\"start\"]\n",
    "                    word[phoneme_idx + j][\"syllable_stop\"] = syllable_dict[\"stop\"]\n",
    "\n",
    "                syllable_dicts.append(syllable_dict)\n",
    "                phoneme_idx += len(syllable_phones)\n",
    "                syllable_idx += 1\n",
    "        else:\n",
    "            syllable_dicts = []\n",
    "\n",
    "        word_syllables.append(syllable_dicts)\n",
    "    \n",
    "    item[\"word_syllable_detail\"] = word_syllables\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_item(item, idx, drop_phones=None):\n",
    "    try:\n",
    "        grouped_phonemic_detail = item[\"word_phonemic_detail\"]\n",
    "        grouped_syllable_detail = item[\"word_syllable_detail\"]\n",
    "        assert len(grouped_phonemic_detail) == len(item[\"word_detail\"][\"utterance\"])\n",
    "        assert len(grouped_syllable_detail) == len(item[\"word_detail\"][\"utterance\"])\n",
    "\n",
    "        all_phonemes = [phon[\"phone\"] for word in grouped_phonemic_detail for phon in word]\n",
    "        all_phonemes_syll = [phone for word in item[\"word_syllable_detail\"] for syllable in word for phone in syllable[\"phones\"]]\n",
    "        assert len(all_phonemes) == len(all_phonemes_syll)\n",
    "        assert all_phonemes == all_phonemes_syll, \"phonemic detail does not match phonemes within syllable detail\"\n",
    "\n",
    "        # NB we do expect a mismatch here since some phonemes in the flat representation\n",
    "        # won't appear in the word grouped representation, if they are outside the span of a word\n",
    "        # all_phonemes_flat = [ph for ph in item[\"phonemic_detail\"][\"utterance\"] if ph not in (drop_phones or [])]\n",
    "        # assert all_phonemes == all_phonemes_flat, \\\n",
    "        #     f\"grouped phonemic detail does not match non-grouped phonemic detail in item {idx}:\" \\\n",
    "        #     f\"\\n{item['text']}\\n{all_phonemes}\\n{all_phonemes_flat}\"\n",
    "    except Exception as e:\n",
    "        L.error(f\"Error in item {idx} ({item['text']})\")\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_audio(batch):\n",
    "    audio = batch[\"audio\"]\n",
    "    batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_idx(item, idx):\n",
    "    item[\"idx\"] = idx\n",
    "    item[\"split\"] = split\n",
    "\n",
    "    return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_phones = [\"sil\", \"sp\", \"spn\", \"\"]\n",
    "\n",
    "dev_dataset = dev_dataset.map(americanize_item_orthography)\n",
    "dev_dataset = dev_dataset.map(add_phonemic_detail)\n",
    "dev_dataset = dev_dataset.map(group_phonetic_detail, with_indices=True,\n",
    "                              fn_kwargs=dict(drop_phones=drop_phones))\n",
    "dev_dataset = dev_dataset.map(group_phonetic_detail, with_indices=True,\n",
    "                              fn_kwargs=dict(key=\"phonemic_detail\", drop_phones=drop_phones))\n",
    "\n",
    "dev_dataset = dev_dataset.map(add_syllabic_detail)\n",
    "\n",
    "dev_dataset.map(check_item, with_indices=True)\n",
    "\n",
    "dev_dataset = dev_dataset.map(prepare_audio)\n",
    "dev_dataset = dev_dataset.map(add_idx, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_item(item_idx, ax, plot_units=\"phoneme\", viz_rate=1000):\n",
    "    item = dev_dataset[item_idx]\n",
    "\n",
    "    times = np.linspace(0, len(item[\"input_values\"]) / 16000, int(len(item[\"input_values\"]) / 16000 * viz_rate))\n",
    "    # normalize to [-1, 1]\n",
    "    values = np.array(item[\"input_values\"])\n",
    "    values = (values - values.min()) / (values.max() - values.min()) * 2 - 1\n",
    "    # resample to viz frame rate\n",
    "    values = np.interp(times, np.arange(len(values)) / 16000, values)\n",
    "    ax.plot(times, values, alpha=0.2)\n",
    "\n",
    "    # plot word and phoneme boundaries\n",
    "    for i, word in enumerate(item[\"word_phonemic_detail\"]):\n",
    "        if not word:\n",
    "            continue\n",
    "        word_str = item[\"word_detail\"][\"utterance\"][i]\n",
    "\n",
    "        word_start, word_stop = word[0][\"start\"] / 16000, word[-1][\"stop\"] / 16000\n",
    "        ax.axvline(word_start, color=\"black\", linestyle=\"--\")\n",
    "        ax.text(word_start, 0.8, word_str, rotation=90, verticalalignment=\"bottom\", alpha=0.7)\n",
    "\n",
    "        if plot_units == \"phoneme\":\n",
    "            for j, phoneme in enumerate(word):\n",
    "                phoneme_str = phoneme[\"phone\"]\n",
    "                phoneme_start, phoneme_stop = phoneme[\"start\"] / 16000, phoneme[\"stop\"] / 16000\n",
    "\n",
    "                if j > 0:\n",
    "                    color = \"black\" if phoneme[\"idx_in_syllable\"] == 0 else \"gray\"\n",
    "                    ax.axvline(phoneme_start, color=color, linestyle=\":\", alpha=0.5)\n",
    "                ax.text(phoneme_start + 0.01, -6, phoneme_str, rotation=90, verticalalignment=\"bottom\",\n",
    "                        fontdict={\"size\": 15})\n",
    "        elif plot_units == \"syllable\":\n",
    "            for j, syllable in enumerate(item[\"word_syllable_detail\"][i]):\n",
    "                syllable_str = \" \".join(syllable[\"phones\"])\n",
    "                syllable_start, syllable_stop = syllable[\"start\"] / 16000, syllable[\"stop\"] / 16000\n",
    "\n",
    "                if j > 0:\n",
    "                    ax.axvline(syllable_start, color=\"black\", linestyle=\":\", alpha=0.5)\n",
    "                ax.text(syllable_start + 0.01, -6, syllable_str, rotation=90, verticalalignment=\"bottom\",\n",
    "                        fontdict={\"size\": 15})\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown plot_units: {plot_units}\")\n",
    "\n",
    "    # align at origin\n",
    "    ax.set_ylim((-8, 8))\n",
    "\n",
    "    ax.set_title(f\"{item['speaker_id']}_{item['id']}: {item['text']}\")\n",
    "    ax.set_yticks([])\n",
    "    ax.grid(False)\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(2, 1, figsize=(25, 2 * 8))\n",
    "idx = np.random.choice(len(dev_dataset))\n",
    "print(idx)\n",
    "plot_item(idx, axs[0], plot_units=\"phoneme\")\n",
    "plot_item(idx, axs[1], plot_units=\"syllable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check word-level correspondence with CMUdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "from tempfile import NamedTemporaryFile\n",
    "from urllib.request import urlretrieve\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "# Download and parse cmudict\n",
    "cmudict_entries = defaultdict(list)\n",
    "with NamedTemporaryFile() as f:\n",
    "    urlretrieve(\"https://github.com/cmusphinx/cmudict/raw/master/cmudict.dict\", f.name)\n",
    "\n",
    "    with open(f.name, \"r\") as f:\n",
    "        for line in f:\n",
    "            # remove comments\n",
    "            line = re.sub(r'(\\s)*#.*', '', line)\n",
    "\n",
    "            fields = line.strip().split(\" \")\n",
    "            word = fields[0]\n",
    "\n",
    "            # remove word idx number, indicating secondary pronunciation\n",
    "            word = re.sub(r\"\\(\\d\\)$\", \"\", word)\n",
    "\n",
    "            phones = tuple(fields[1:])\n",
    "            # remove stress markers\n",
    "            phones = tuple(re.sub(r\"\\d\", \"\", p) for p in phones)\n",
    "\n",
    "            cmudict_entries[word].append(phones)\n",
    "\n",
    "cmudict_entries = dict(cmudict_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track attested pronunciations of each word in corpus\n",
    "corpus_cmudict_mapping = defaultdict(Counter)\n",
    "def process_item(item):\n",
    "    for word, word_phonemes in zip(item[\"word_detail\"][\"utterance\"], item[\"word_phonemic_detail\"]):\n",
    "        corpus_cmudict_mapping[word.lower()][tuple(p[\"phone\"] for p in word_phonemes)] += 1\n",
    "\n",
    "dev_dataset.map(process_item)\n",
    "corpus_cmudict_mapping = dict(corpus_cmudict_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many words have multiple pronunciations?\n",
    "multiple_pronunciations = {k: v for k, v in corpus_cmudict_mapping.items() if len(v) > 1}\n",
    "print(f\"{len(multiple_pronunciations)} words ({len(multiple_pronunciations) / len(corpus_cmudict_mapping) * 100}%) have multiple pronunciations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many words have CMUDICT pronunciations?\n",
    "has_cmudict = {k: v for k, v in corpus_cmudict_mapping.items() if k in cmudict_entries}\n",
    "print(f\"{len(has_cmudict)} words ({len(has_cmudict) / len(corpus_cmudict_mapping) * 100}%) have CMUDICT pronunciations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For how many words does the majority pronunciation align with the CMUDICT pronunciation?\n",
    "majority_aligned = {k: v for k, v in corpus_cmudict_mapping.items()\n",
    "                    if len(cmudict_entries.get(k, [])) > 0 and v.most_common(1)[0][0] == cmudict_entries[k][0]}\n",
    "majority_misaligned = {k: v for k, v in corpus_cmudict_mapping.items()\n",
    "                       if len(cmudict_entries.get(k, [])) > 0 and v.most_common(1)[0][0] != cmudict_entries[k][0]}\n",
    "print(f\"{len(majority_aligned)} words ({len(majority_aligned) / len(corpus_cmudict_mapping) * 100}%) have majority-aligned CMUDICT pronunciations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For misaligned majorities, compare with CMUDICT\n",
    "for word, counts in majority_misaligned.items():\n",
    "    print(f\"{word}: {' '.join(counts.most_common(1)[0][0])} (LibriSpeech) vs {' '.join(cmudict_entries[word][0])} (CMUDICT)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect orthographic forms by their majority pronunciation\n",
    "pronunciation_to_words = defaultdict(list)\n",
    "for word, counts in corpus_cmudict_mapping.items():\n",
    "    pronunciation, count = counts.most_common(1)[0]\n",
    "    pronunciation_to_words[pronunciation].append((word, count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many distinct orthographic forms have highly overlapping phonological realizations? make sure there aren't too many of\n",
    "# these -- these are cases like \"honour\" vs \"honor\" that really shouldn't be distinguished\n",
    "# so spot-check that the frequent ones are genuine homophones, not transcription inconsistencies\n",
    "sorted(list({k: vs for k, vs in pronunciation_to_words.items() if len(vs) > 1}.items()),\n",
    "       key=lambda kv: sum(v[1] for v in kv[1]), reverse=True)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_cmudict_entropy = {}\n",
    "for word, counts in corpus_cmudict_mapping.items():\n",
    "    total_count = sum(counts.values())\n",
    "    entropy = -sum(count / total_count * np.log2(count / total_count) for count in counts.values())\n",
    "    corpus_cmudict_entropy[word] = entropy\n",
    "\n",
    "corpus_cmudict_entropy = pd.Series(corpus_cmudict_entropy).sort_values(ascending=False)\n",
    "corpus_cmudict_entropy.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syllable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_syllable_counts = Counter()\n",
    "word_syllable_counts = defaultdict(Counter)\n",
    "\n",
    "def process_item(item):\n",
    "    for i, (word, syllables) in enumerate(zip(item[\"word_detail\"][\"utterance\"], item[\"word_syllable_detail\"])):\n",
    "        syll_string = tuple(tuple(syllable[\"phones\"]) for syllable in syllables)\n",
    "        word_syllable_counts[word.lower()][syll_string] += 1\n",
    "        for syllable in syll_string:\n",
    "            all_syllable_counts[syllable] += 1\n",
    "dev_dataset.map(process_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_syllable_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmudict_vowels = {\"AA\", \"AE\", \"AH\", \"AO\", \"AW\", \"AY\", \"EH\", \"ER\", \"EY\", \"IH\", \"IY\", \"OW\", \"OY\", \"UH\", \"UW\"}\n",
    "\n",
    "print(\"Syllabic consonant frequencies:\")\n",
    "syllabic_frequencies = Counter({k: v for k, v in all_syllable_counts.items() if len(k) == 1 and k[0] not in cmudict_vowels})\n",
    "pprint(syllabic_frequencies)\n",
    "\n",
    "print(\"Proportion of total syllable tokens: \", sum(syllabic_frequencies.values()) / sum(all_syllable_counts.values()) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_syllabification_words = Counter({k: v for k, v in word_syllable_counts.items() if len(v) > 1})\n",
    "print(f\"{len(multiple_syllabification_words)} words ({len(multiple_syllabification_words) / len(word_syllable_counts) * 100}%) have multiple syllabifications\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log top token frequency syllables\n",
    "sorted(multiple_syllabification_words.items(), key=lambda x: sum(x[1].values()), reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset.save_to_disk(out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
