{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "import duckdb\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from src.analysis.state_space import StateSpaceAnalysisSpec\n",
    "from src.utils import concat_csv_with_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context(\"talk\", font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "dataset = \"librispeech-train-clean-100\"\n",
    "state_space_name = \"word\"\n",
    "\n",
    "# base_model = \"w2v2_8\"\n",
    "# model_class = \"rnn_8-weightdecay0.01\"\n",
    "# model_name = \"phoneme\"\n",
    "\n",
    "base_model = \"w2v2_8\"\n",
    "model_class = \"rnn_32-hinge-mAP4\"\n",
    "model_name = \"word_broad\"\n",
    "\n",
    "model_dir = f\"outputs/models/{dataset}/{base_model}/{model_class}/{model_name}_10frames\"\n",
    "output_dir = f\"outputs/notebooks/{dataset}/{base_model}/{model_class}/{model_name}_10frames/word_discrimination\"\n",
    "dataset_path = f\"outputs/preprocessed_data/{dataset}\"\n",
    "equivalence_path = f\"outputs/equivalence_datasets/{dataset}/{base_model}/{model_name}_10frames/equivalence.pkl\"\n",
    "hidden_states_path = f\"outputs/hidden_states/{dataset}/{base_model}/hidden_states.h5\"\n",
    "state_space_specs_path = f\"outputs/state_space_specs/{dataset}/{base_model}/state_space_specs.h5\"\n",
    "embeddings_path = f\"outputs/model_embeddings/{dataset}/{base_model}/{model_class}/{model_name}_10frames/{dataset}.npy\"\n",
    "\n",
    "recognition_model = \"linear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space_spec = StateSpaceAnalysisSpec.from_hdf5(state_space_specs_path, state_space_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = Path(dataset_path).name\n",
    "model_trace = Path(model_dir).relative_to(Path(model_dir).parents[2])\n",
    "\n",
    "dataset_name, model_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = concat_csv_with_indices(\n",
    "    f\"outputs/word_recognition/{dataset_name}/{model_trace}/{dataset_name}/{recognition_model}/predictions-frame_*.csv\",\n",
    "    [re.compile(r\"frame_(\\d+).csv\")], [\"frame_idx\"]) \\\n",
    "        .droplevel(-1).reset_index()\n",
    "predictions_df[\"frame_idx\"] = predictions_df.frame_idx.astype(int)\n",
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chance_performance = predictions_df.groupby(\"frame_idx\") \\\n",
    "    .apply(lambda x: x.label.value_counts(normalize=True).max()).rename(\"chance_performance\")\n",
    "chance_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df = predictions_df.groupby(\"frame_idx\").correct.mean().reset_index()\n",
    "acc_df[\"num_frames\"] = acc_df.frame_idx + 1\n",
    "acc_df.to_csv(Path(output_dir) / \"accuracy.csv\", index=False)\n",
    "ax = sns.lineplot(data=acc_df, x=\"num_frames\", y=\"correct\")\n",
    "\n",
    "ax.set_xlabel(\"# phonemes seen\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "\n",
    "# draw chance performance as a horizontal line over each x value\n",
    "for frame, frame_chance_perf in chance_performance.items():\n",
    "    ax.plot([frame + 1, frame + 2], [frame_chance_perf, frame_chance_perf],\n",
    "            color=\"gray\", linestyle=\"--\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_df = predictions_df.loc[predictions_df.label != predictions_df.predicted_label]\n",
    "confusion_df[\"confusion\"] = confusion_df.label + \" -> \" + confusion_df.predicted_label\n",
    "confusion_df = confusion_df.groupby(\"frame_idx\").confusion.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEV\n",
    "confusion_df = confusion_df.to_frame().reset_index()\n",
    "confusion_df[[\"label\", \"predicted_label\"]] = confusion_df.confusion.str.split(\" -> \", expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEV\n",
    "confusion_df[\"ok\"] = (confusion_df.label == confusion_df.predicted_label + \"s\") | (confusion_df.label + \"s\" == confusion_df.predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect_df = confusion_df[~confusion_df.ok].sort_values(\"proportion\", ascending=False).set_index(\"frame_idx\").sort_index()\n",
    "inspect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame_idx, frame_confusions in confusion_df.groupby(\"frame_idx\"):\n",
    "    print(frame_idx)\n",
    "    print(frame_confusions.sort_values(\"proportion\", ascending=False).head(40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_df.sample(20).reset_index().sort_values('frame_idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df[~predictions_df.correct] \\\n",
    "    .groupby(\"frame_idx\", as_index=False)[[\"frame_idx\", \"label\", \"predicted_label\"]].sample(40, replace=True) \\\n",
    "    .sort_values(\"frame_idx\") \\\n",
    "    .to_csv(Path(output_dir) / \"confusions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time-course of identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_labels = np.random.choice(predictions_df.label.unique(), 16, replace=False)\n",
    "num_cols = 2\n",
    "num_rows = int(np.ceil(len(study_labels) / num_cols))\n",
    "f, axs = plt.subplots(num_rows, num_cols, figsize=(26, 8 * num_rows))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "word_font_size = plt.rcParams[\"font.size\"] * 0.8\n",
    "\n",
    "for ax, label in zip(tqdm(axs.flat), study_labels):\n",
    "    label_rows = predictions_df.loc[predictions_df.label == label]\n",
    "    instance_trajs = [instance_rows.correct.values for _, instance_rows in label_rows.groupby(\"label_instance_idx\")]\n",
    "    instance_predictions = [instance_rows.predicted_label.values for _, instance_rows in label_rows.groupby(\"label_instance_idx\")]\n",
    "    # pad\n",
    "    max_len = max(len(traj) for traj in instance_trajs)\n",
    "    instance_trajs = np.array([np.pad(traj, (0, max_len - len(traj))) for traj in instance_trajs])\n",
    "\n",
    "    ax.axhline(0.5, color=\"gray\", linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    # plot words at transitions from correct to incorrect\n",
    "    frame_prediction_changes = (np.diff(instance_trajs.astype(int), axis=1) == -1).nonzero()\n",
    "    for instance_iloc, frame_idx in zip(*frame_prediction_changes):\n",
    "        if frame_idx + 1 < len(instance_predictions[instance_iloc]):\n",
    "            ax.text(frame_idx + 2, 0 + np.random.random() * 0.2 - 0.1,\n",
    "                    instance_predictions[instance_iloc][frame_idx + 1],\n",
    "                    color=\"red\", ha=\"center\", size=word_font_size)\n",
    "\n",
    "    # plot initial mistakes\n",
    "    initial_mistakes = (instance_trajs[:, 0] == 0).nonzero()[0]\n",
    "    initial_mistakes_y = np.linspace(-0.3, 0.7, len(initial_mistakes))\n",
    "    for instance_iloc, text_y in zip(initial_mistakes, initial_mistakes_y):\n",
    "        ax.text(1 - 0.15, text_y,\n",
    "                instance_predictions[instance_iloc][0],\n",
    "                color=\"red\", ha=\"left\", size=word_font_size)\n",
    "\n",
    "    ax.set_title(label)\n",
    "    ax.plot(list(range(1, max_len + 1)), instance_trajs.T + np.random.random((1, instance_trajs.shape[0])) * 0.1, alpha=0.5)\n",
    "    ax.plot(list(range(1, max_len + 1)), instance_trajs.mean(axis=0), color=\"black\", linewidth=4)\n",
    "\n",
    "    ax.set_xlabel(\"# phonemes seen\")\n",
    "    ax.set_xticks(list(range(1, max_len + 1)))\n",
    "    ax.set_ylim(-0.1, 1.1)\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_yticklabels([\"Incorrect\", \"Correct\"])\n",
    "\n",
    "f.savefig(Path(output_dir) / \"prediction_time_courses.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lexical effects in recognition time course"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq_df = pd.read_csv(\"data/SUBTLEXus74286wordstextversion.txt\", sep=\"\\t\", index_col=0)\n",
    "num_frequency_bins = 6\n",
    "word_freq_df[\"log_frequency_bin\"] = pd.qcut(word_freq_df.Lg10WF, num_frequency_bins, duplicates=\"drop\")\n",
    "word_frequency_bins = word_freq_df.log_frequency_bin.cat.categories\n",
    "word_freq_df[\"log_frequency_bin\"] = word_freq_df[\"log_frequency_bin\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_frequency_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_meta = pd.merge(predictions_df, word_freq_df, left_on=\"label\", right_index=True)\n",
    "predictions_df_meta[\"# phonemes seen\"] = predictions_df_meta.frame_idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=predictions_df_meta,\n",
    "             x=\"# phonemes seen\", y=\"correct\", hue=\"log_frequency_bin\", palette=\"viridis\")\n",
    "ax.legend(title=\"Word frequency bin\", loc=\"upper left\", bbox_to_anchor=(1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance on words in each frequency bin\n",
    "predictions_df_meta \\\n",
    "    .groupby([\"log_frequency_bin\", \"label\", \"label_instance_idx\"]).correct.max() \\\n",
    "    .groupby([\"log_frequency_bin\", \"label\"]).filter(lambda x: len(x) > 10) \\\n",
    "    .groupby([\"log_frequency_bin\", \"label\"]).mean() \\\n",
    "    .groupby(\"log_frequency_bin\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-predicted words per frequency bin\n",
    "predictions_df_meta \\\n",
    "    .groupby(\"label\").filter(lambda x: len(x) > 10) \\\n",
    "    .groupby([\"log_frequency_bin\", \"label\", \"label_instance_idx\"]).correct.max() \\\n",
    "    .groupby([\"log_frequency_bin\", \"label\"]).mean().sort_values() \\\n",
    "    .groupby(\"log_frequency_bin\").tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample of prediction performance per frequency bin\n",
    "predictions_df_meta \\\n",
    "    .groupby(\"label\").filter(lambda x: len(x) > 10) \\\n",
    "    .groupby([\"log_frequency_bin\", \"label\", \"label_instance_idx\"]).correct.max() \\\n",
    "    .groupby([\"log_frequency_bin\", \"label\"]).mean().sort_values() \\\n",
    "    .groupby(\"log_frequency_bin\").sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohort size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't save the actual training set which is a subsample of the full state space spec.\n",
    "# We thus won't be able to get item-level stats on cohort of a particular word pronunciation.\n",
    "# But we can get the expected / marginal case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = state_space_spec.cuts.xs(\"phoneme\", level=\"level\").reset_index()\n",
    "dev_df[\"phoneme_idx\"] = dev_df.groupby([\"label\", \"instance_idx\"]).cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset temporary tables\n",
    "duckdb.query(\"DROP TABLE IF EXISTS phoneme_sequences; DROP TABLE IF EXISTS cohorts;\")\n",
    "\n",
    "# get a table of cohort sizes\n",
    "cohorts = duckdb.query(\"\"\"\n",
    "    -- Step 1: Create a temporary table with concatenated descriptions and their lengths\n",
    "    CREATE TEMPORARY TABLE phoneme_sequences AS\n",
    "    SELECT \n",
    "        label, \n",
    "        instance_idx, \n",
    "        STRING_AGG(description, ' ' ORDER BY phoneme_idx) AS phoneme_seq,\n",
    "        LENGTH(STRING_AGG(description, ' ')) - LENGTH(REPLACE(STRING_AGG(description, ' '), ' ', '')) + 1 AS phoneme_count\n",
    "    FROM dev_df\n",
    "    GROUP BY label, instance_idx;\n",
    "\n",
    "    -- Step 2: Create cohorts table\n",
    "    CREATE TEMPORARY TABLE cohorts AS\n",
    "    WITH recursive cohorts_cte AS (\n",
    "        SELECT \n",
    "            label,\n",
    "            instance_idx,\n",
    "            phoneme_seq,\n",
    "            SPLIT_PART(phoneme_seq, ' ', 1) AS prefix,\n",
    "            phoneme_count,\n",
    "            1 AS prefix_length\n",
    "        FROM phoneme_sequences\n",
    "        UNION ALL\n",
    "        SELECT \n",
    "            label,\n",
    "            instance_idx,\n",
    "            phoneme_seq,\n",
    "            TRIM(prefix || ' ' || REGEXP_EXTRACT(SUBSTRING(phoneme_seq FROM LENGTH(prefix) + 2), '^[^ ]+')) AS prefix,\n",
    "            phoneme_count,\n",
    "            prefix_length + 1\n",
    "        FROM cohorts_cte\n",
    "        WHERE prefix_length < phoneme_count\n",
    "    )\n",
    "    SELECT \n",
    "        prefix AS phoneme_prefix,\n",
    "        label,\n",
    "        COUNT(*) AS count\n",
    "    FROM cohorts_cte\n",
    "    GROUP BY phoneme_prefix, label;\n",
    "             \n",
    "    SELECT * FROM cohorts;\n",
    "    \"\"\").to_df().set_index([\"phoneme_prefix\", \"label\"]).sort_index()\n",
    "\n",
    "cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.query(\"DROP TABLE IF EXISTS phoneme_sequences; DROP TABLE IF EXISTS cohorts;\")\n",
    "articulation_df = duckdb.query(\"\"\"\n",
    "    -- Step 1: Create a temporary table with concatenated descriptions and their lengths\n",
    "    CREATE TEMPORARY TABLE phoneme_sequences AS\n",
    "    SELECT\n",
    "        label,\n",
    "        phoneme_seq,\n",
    "        COUNT(*) AS count\n",
    "    FROM (\n",
    "        SELECT label, \n",
    "            instance_idx, \n",
    "            STRING_AGG(description, ' ' ORDER BY phoneme_idx) AS phoneme_seq,\n",
    "            LENGTH(STRING_AGG(description, ' ')) - LENGTH(REPLACE(STRING_AGG(description, ' '), ' ', '')) + 1 AS phoneme_count\n",
    "        FROM dev_df\n",
    "        GROUP BY label, instance_idx)\n",
    "    GROUP BY label, phoneme_seq;\n",
    "             \n",
    "    SELECT label, phoneme_seq, count / SUM(count) OVER (PARTITION BY label) AS proportion\n",
    "    FROM phoneme_sequences;\"\"\").to_df().dropna()\n",
    "articulation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix2idx = {prefix: idx for idx, prefix in enumerate(sorted(cohorts.index.get_level_values(\"phoneme_prefix\").unique()))}\n",
    "idx2prefix = {idx: prefix for prefix, idx in prefix2idx.items()}\n",
    "idx2word = sorted(articulation_df.label.unique())\n",
    "word2idx = {word: idx for idx, word in enumerate(idx2word)}\n",
    "\n",
    "prefix_mat = sp.dok_matrix((len(word2idx), len(prefix2idx)))\n",
    "\n",
    "for _, row in articulation_df.iterrows():\n",
    "    phoneme_seq = row.phoneme_seq.split(\" \")\n",
    "    for prefix_length in range(1, len(phoneme_seq) + 1):\n",
    "        prefix_mat[word2idx[row.label], prefix2idx[\" \".join(phoneme_seq[:prefix_length])]] += row.proportion\n",
    "\n",
    "prefix_mat = prefix_mat.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_sizes = prefix_mat.sum(axis=0).A1\n",
    "cohort_entropies = -(prefix_mat / prefix_mat.sum(axis=0)).multiply((prefix_mat / prefix_mat.sum(axis=0)).log1p()).sum(axis=0).A1\n",
    "cohort_entropies[np.isnan(cohort_entropies)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[idx2prefix[idx] for idx in (-cohort_sizes).argsort()[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct masks for each frame idx\n",
    "frame_idx_masks = np.stack([np.array([1 if prefix.count(\" \") == frame_idx else 0 for prefix in idx2prefix.values()]) for frame_idx in range(10)]).T\n",
    "frame_idx_masks.shape\n",
    "\n",
    "incremental_cohort_sizes = prefix_mat.multiply(cohort_sizes).dot(frame_idx_masks)\n",
    "incremental_cohort_entropies = prefix_mat.multiply(cohort_entropies).dot(frame_idx_masks)\n",
    "\n",
    "articulation_df[\"num_phonemes\"] = articulation_df.phoneme_seq.str.count(\" \") + 1\n",
    "word_max_lengths = articulation_df.groupby(\"label\").num_phonemes.max()\n",
    "\n",
    "# Create a mask on the derived cohort stats for phonemes never attested\n",
    "attested_mask = np.zeros_like(incremental_cohort_sizes, dtype=bool)\n",
    "for word, max_length in word_max_lengths.items():\n",
    "    attested_mask[word2idx[word], max_length:] = True\n",
    "\n",
    "incremental_cohort_sizes[attested_mask] = np.nan\n",
    "incremental_cohort_entropies[attested_mask] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_size_df = pd.DataFrame(incremental_cohort_sizes, index=pd.Index(idx2word, name=\"label\")).reset_index().melt(id_vars=[\"label\"], var_name=\"frame_idx\", value_name=\"cohort_size\")\n",
    "cohort_entropy_df = pd.DataFrame(incremental_cohort_entropies, index=pd.Index(idx2word, name=\"label\")).reset_index().melt(id_vars=[\"label\"], var_name=\"frame_idx\", value_name=\"cohort_entropy\")\n",
    "cohort_meta_df = pd.merge(cohort_size_df, cohort_entropy_df)\n",
    "cohort_meta_df = cohort_meta_df.dropna()\n",
    "\n",
    "cohort_meta_df[\"cohort_size_bin\"] = pd.qcut(cohort_meta_df.cohort_size, 5, duplicates=\"drop\")\n",
    "cohort_meta_df[\"cohort_size_bin\"] = cohort_meta_df.cohort_size_bin.cat.codes.astype(str)\n",
    "cohort_meta_df[\"cohort_entropy_bin\"] = pd.qcut(cohort_meta_df.cohort_entropy, 5, duplicates=\"drop\")\n",
    "cohort_meta_df[\"cohort_entropy_bin\"] = cohort_meta_df.cohort_entropy_bin.cat.codes.astype(str)\n",
    "cohort_meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df_meta = pd.merge(predictions_df, cohort_meta_df, on=[\"label\", \"frame_idx\"], how=\"left\")\n",
    "predictions_df_meta[\"# phonemes seen\"] = predictions_df_meta.frame_idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.lineplot(data=predictions_df_meta, x=\"# phonemes seen\", y=\"correct\", hue=\"cohort_size_bin\", hue_order=sorted(cohort_meta_df.cohort_size_bin.unique()),\n",
    "                  palette=\"viridis\")\n",
    "ax.legend(title=\"Cohort size bin\", loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "ax.set_xticks(list(range(1, 11)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=predictions_df_meta, x=\"frame_idx\", y=\"correct\", hue=\"cohort_entropy_bin\", hue_order=sorted(cohort_meta_df.cohort_entropy_bin.unique()),\n",
    "             palette=\"viridis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neighborhood density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aelp_df = pd.read_csv(\"data/aelp.csv\", index_col=0)\n",
    "\n",
    "aelp_df[\"phono_dens_bin\"] = pd.qcut(aelp_df.phono_n_dens_s, 5, duplicates=\"drop\")\n",
    "print(aelp_df.phono_dens_bin.cat.categories)\n",
    "aelp_df[\"phono_dens_bin\"] = aelp_df.phono_dens_bin.cat.codes\n",
    "aelp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aelp_df_merged = pd.merge(predictions_df_meta, aelp_df, left_on=\"label\", right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aelp_df_merged.groupby(\"phono_dens_bin\").sample(5)[[\"label\", \"phono_dens_bin\", \"phono_n_dens_s\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=aelp_df_merged, x=\"frame_idx\", y=\"correct\", hue=\"phono_dens_bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognition point analysis (intrinsic/probabilistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognition_intrinsic_threshold = 0.6\n",
    "predictions_df[\"recognized\"] = predictions_df.predicted_probability >= recognition_intrinsic_threshold\n",
    "predictions_df[\"recognized_gt\"] = predictions_df.correct & (predictions_df.predicted_probability >= recognition_intrinsic_threshold)\n",
    "\n",
    "recognition_criteria = [\"recognized\", \"recognized_gt\"]\n",
    "# intrinsic_recognition_points = predictions_df.groupby([\"label\", \"label_instance_idx\"]).apply(\n",
    "#     lambda xs: pd.Series(xs[recognition_measures].values.argmax(0) * xs[recognition_measures].any(axis=0).map({True: 1, False: np.nan}).values, index=recognition_measures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get first frame within label, label_instance_idx where recognition is achieved under recognized_gt measure\n",
    "recognition_point_df = pd.concat({\n",
    "    criterion_name: duckdb.query(f\"\"\"\n",
    "            SELECT label, label_instance_idx, MIN(frame_idx) AS frame_idx\n",
    "            FROM predictions_df\n",
    "            WHERE {criterion_name}\n",
    "            GROUP BY label, label_instance_idx;\n",
    "        \"\"\").to_df().set_index([\"label\", \"label_instance_idx\"]).rename(columns={\"frame_idx\": \"recognition_point\"})\n",
    "    for criterion_name in recognition_criteria\n",
    "}, names=[\"criterion\"]).unstack(\"criterion\").sort_index()\n",
    "recognition_point_df.columns = recognition_point_df.columns.droplevel(0)\n",
    "recognition_point_df.columns = [f\"{criterion}_point\" for criterion in recognition_point_df.columns]\n",
    "recognition_point_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=recognition_point_df.reset_index().melt(id_vars=[\"label\", \"label_instance_idx\"]), x=\"value\", col=\"variable\", discrete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add AELP metadata\n",
    "aelp_vars = [\"phono_n_dens_s\", \"phono_n_freq_s_m\", \"phono_upoint\",\n",
    "             \"lgsubtlwf\", \"n_phon\", \"sum_biphone\"]\n",
    "recognition_point_df = pd.merge(recognition_point_df.reset_index(), aelp_df, left_on=\"label\", right_on=\"word_us\")[[\"label\", \"label_instance_idx\"] + aelp_vars + [f\"{x}_point\" for x in recognition_criteria]].reset_index()\n",
    "recognition_point_df.to_csv(f\"{output_dir}/recognition_points.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data = recognition_point_df[aelp_vars + [\"recognized_gt_point\"]].reset_index().melt(id_vars=[\"index\", \"recognized_gt_point\"])\n",
    "plot_data = plot_data[~plot_data.recognized_gt_point.isna()]\n",
    "if len(plot_data) == 0:\n",
    "    print(\"Nothing to plot. Stop.\")\n",
    "else:\n",
    "    # jitter\n",
    "    plot_data[\"value_jitter\"] = plot_data.value + np.random.normal(0, 0.05, len(plot_data))\n",
    "    plot_data[\"recognition_point_jitter\"] = plot_data.recognized_gt_point + np.random.normal(0, 0.05, len(plot_data))\n",
    "    g = sns.relplot(data=plot_data,\n",
    "                    x=\"recognition_point_jitter\", y=\"value_jitter\", col=\"variable\", col_wrap=2,\n",
    "                    kind=\"scatter\", facet_kws=dict(sharey=False))\n",
    "\n",
    "    for hue, ax in g.axes_dict.items():\n",
    "        # line of best fit\n",
    "        sns.lineplot(data=plot_data[plot_data.variable == hue],\n",
    "                    x=\"recognized_gt_point\", y=\"value\", ax=ax, color=\"black\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recognition point analysis (extrinsic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognition_threshold = 0.7\n",
    "recognition_count_threshold = 10\n",
    "\n",
    "recognition_df = predictions_df \\\n",
    "    .groupby(\"label\").filter(lambda xs: len(xs) >= recognition_count_threshold) \\\n",
    "    .groupby([\"label\", \"frame_idx\"]).correct.mean() > recognition_threshold\n",
    "# filter out words which never pass threshold\n",
    "# then compute first frame at which we pass threshold\n",
    "recognition_points = recognition_df.groupby(\"label\").filter(lambda x: x.any()) \\\n",
    "    .groupby(\"label\").idxmax().str[1].rename(\"recognition_point\")\n",
    "\n",
    "sns.boxenplot(recognition_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vars = [\"phono_n_dens_s\", \"phono_n_freq_s_m\", \"phono_upoint\",\n",
    "            \"lgsubtlwf\", \"n_phon\", \"sum_biphone\"]\n",
    "plot_data = pd.merge(recognition_points, aelp_df, left_index=True, right_index=True)[plot_vars + [\"recognition_point\"]].reset_index().melt(id_vars=[\"index\", \"recognition_point\"])\n",
    "if len(plot_data) == 0:\n",
    "    print(\"Nothing to plot. Stop.\")\n",
    "else:\n",
    "    # jitter\n",
    "    plot_data[\"value_jitter\"] = plot_data.value + np.random.normal(0, 0.05, len(plot_data))\n",
    "    plot_data[\"recognition_point_jitter\"] = plot_data.recognition_point + np.random.normal(0, 0.05, len(plot_data))\n",
    "    g = sns.relplot(data=plot_data,\n",
    "                    x=\"recognition_point_jitter\", y=\"value_jitter\", col=\"variable\", col_wrap=2,\n",
    "                    kind=\"scatter\", facet_kws=dict(sharey=False))\n",
    "\n",
    "    for hue, ax in g.axes_dict.items():\n",
    "        # line of best fit\n",
    "        sns.lineplot(data=plot_data[plot_data.variable == hue],\n",
    "                    x=\"recognition_point\", y=\"value\", ax=ax, color=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognition_points.drop(columns=[\"value_jitter\", \"recognition_point_jitter\"]) \\\n",
    "    .to_csv(Path(output_dir) / f\"recognition_points-threshold{recognition_threshold}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
